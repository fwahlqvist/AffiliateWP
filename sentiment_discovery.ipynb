{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment-discovery.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwahlqvist/AffiliateWP/blob/master/sentiment_discovery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Z4IxbQR8L0BD",
        "colab_type": "code",
        "outputId": "3a36bf67-5613-4826-d862-48b2410fbb07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/sentiment-discovery"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sentiment-discovery'...\n",
            "remote: Enumerating objects: 1133, done.\u001b[K\n",
            "remote: Total 1133 (delta 0), reused 0 (delta 0), pack-reused 1133\u001b[K\n",
            "Receiving objects: 100% (1133/1133), 55.98 MiB | 21.01 MiB/s, done.\n",
            "Resolving deltas: 100% (698/698), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qT9zg-uvL3mD",
        "colab_type": "code",
        "outputId": "5b481168-fac8-4a10-8aa6-ac218fdb4a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gid= \"1aw_gKmowfLaGGxSrhRh0jTuC8gWIOtWP\"\n",
        "gdd.download_file_from_google_drive(file_id=gid,\n",
        "                                    dest_path='./model/ama_32k_tokenizer/a.zip',\n",
        "                                    unzip=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1aw_gKmowfLaGGxSrhRh0jTuC8gWIOtWP into ./model/ama_32k_tokenizer/a.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VIHufyC3MBks",
        "colab_type": "code",
        "outputId": "fbc3349a-4e52-4b35-ac7f-46647b7b589c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "cell_type": "code",
      "source": [
        "gid = \"1ieiWFrYBqzBgGPc3R36x9oL7vlj3lt2F\"\n",
        "gdd.download_file_from_google_drive(file_id=gid,\n",
        "                                    dest_path='./model/mlstm_semeval.clf',\n",
        "                                    unzip=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1ieiWFrYBqzBgGPc3R36x9oL7vlj3lt2F into ./model/mlstm_semeval.clf... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ln5v_v1gMQY6",
        "colab_type": "code",
        "outputId": "538cae98-536a-4345-ec6d-263cd846465f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "cell_type": "code",
      "source": [
        "gid = \"1rC6LWGNkHaZkuojCEWDqSKcDGwFMBTYZ\"\n",
        "gdd.download_file_from_google_drive(file_id=gid,\n",
        "                                    dest_path='./model/transformer_semeval.clf',\n",
        "                                    unzip=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1rC6LWGNkHaZkuojCEWDqSKcDGwFMBTYZ into ./model/transformer_semeval.clf... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nJdwSlD8Pejv",
        "colab_type": "code",
        "outputId": "5cc9d6bc-b7ba-451c-cb24-ad1823f3b374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "cell_type": "code",
      "source": [
        "gid = \"1-lxjFuJm_fQ_DvnxU74-35T_M8WjvrQH\"\n",
        "gdd.download_file_from_google_drive(file_id=gid,\n",
        "                                    dest_path='./model/transformer_sst.clf',\n",
        "                                    unzip=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1-lxjFuJm_fQ_DvnxU74-35T_M8WjvrQH into ./model/transformer_sst.clf... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M75PLFRgPfB2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gid = \"1-lxjFuJm_fQ_DvnxU74-35T_M8WjvrQH\"\n",
        "gdd.download_file_from_google_drive(file_id=gid,\n",
        "                                    dest_path='./model/transformer_semeval.clf',\n",
        "                                    unzip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N2E7sdg5UPYX",
        "colab_type": "code",
        "outputId": "c129a22a-c6f9-462f-b983-676e8fb1f1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "gid = \"142dVGcHePvOMSojVYiRxutbYSeLu_9ym\"\n",
        "gdd.download_file_from_google_drive(file_id=gid,\n",
        "                                    dest_path='./model/mlstm_sst.clf',\n",
        "                                    unzip=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 142dVGcHePvOMSojVYiRxutbYSeLu_9ym into ./model/mlstm_sst.clf... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7QyxT2tqMfcS",
        "colab_type": "code",
        "outputId": "cb82e413-cdeb-4a3f-ebbb-cf778ceb0872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install unidecode --quiet\n",
        "!pip install sentencepiece --quiet\n",
        "!pip install emoji --quiet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 245kB 5.5MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 20.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3vytySVzMpSj",
        "colab_type": "code",
        "outputId": "e4ae3490-3f0d-421d-cc08-2d705aa7daf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "cell_type": "code",
      "source": [
        "!cp ./sentiment-discovery/data/semeval/test.csv ./test.csv\n",
        "!sed -i '15,$d' ./test.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ",Tweetn0,Ilove the world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hvR_OYsKSN35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.DataFrame({\"Tweet\":['I love the world','I hate the world',\"My life is great\",\"Life sucks\"]}).to_csv(\"sample.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rjhdu_1hNEGd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "GUIDE:\n",
        "https://github.com/NVIDIA/sentiment-discovery/issues/56\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "m19e-eoTMYyY",
        "colab_type": "code",
        "outputId": "9d6640a6-799e-45f3-9877-3734db63fb2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "cell_type": "code",
      "source": [
        "!cd sentiment-discovery; python run_classifier.py \\\n",
        "--load ./../model/mlstm_sst.clf \\\n",
        "--data ./../test.csv \\\n",
        "--model \"mLSTM\" \\\n",
        "--write-results ./../result.csv \\\n",
        "--text-key \"Tweet\" \\\n",
        "--tokenizer-type CharacterLevelTokenizer \\\n",
        "--vocab-size 32000 \\\n",
        "--tokenizer-path ./../model/ama_32k_tokenizer/ama_32k_tokenizer.model \\"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "configuring data\n",
            "Creating mlstm\n",
            "init BinaryClassifier with 4096 features\n",
            "WARNING. Setting neurons 1\n",
            "100% 1/1 [00:00<00:00,  2.20it/s]\n",
            "0.664 seconds to transform 13 examples\n",
            "saving predicted probabilities to clf_results.npy\n",
            "writing results to ./../result.csv\n",
            "generating csv at ./../result.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Ns74MWkNNVK",
        "colab_type": "code",
        "outputId": "7fa4d777-5eef-48f7-86e9-cd9c2f3e619a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"result.csv\")\n",
        "df.head(50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>label pred</th>\n",
              "      <th>label prob</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.637494</td>\n",
              "      <td>@Adnan__786__ @AsYouNotWish Dont worry Indian ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.419929</td>\n",
              "      <td>Academy of Sciences, eschews the normally sobe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.503180</td>\n",
              "      <td>I blew that opportunity -__- #mad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.435428</td>\n",
              "      <td>This time in 2 weeks I will be 30... _ÃÃ·Â´</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.785990</td>\n",
              "      <td>#Deppression is real. Partners w/ #depressed p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.301559</td>\n",
              "      <td>@POLITICOEurope Interesting choice of words......</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.442771</td>\n",
              "      <td>@ananavarro CNN should, for sure _ÃÃ·Ã</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.672355</td>\n",
              "      <td>Distance yourself once stretched by your frien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.662112</td>\n",
              "      <td>Be happy. Be confident. Be kind.\\n\\n #Kissable...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.498863</td>\n",
              "      <td>My visit to hospital for care triggered #traum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.775831</td>\n",
              "      <td>Thanks to Dollis Hill's relentless and tenacio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.379827</td>\n",
              "      <td>@xxBambsxx @OriginalFunko @AshWillBradley @Ell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.865065</td>\n",
              "      <td>@MPSNutrition Welcome to #MPSVT! We are deligh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label  label pred  label prob  \\\n",
              "0    -1.0         1.0    0.637494   \n",
              "1    -1.0         0.0    0.419929   \n",
              "2    -1.0         1.0    0.503180   \n",
              "3    -1.0         0.0    0.435428   \n",
              "4    -1.0         1.0    0.785990   \n",
              "5    -1.0         0.0    0.301559   \n",
              "6    -1.0         0.0    0.442771   \n",
              "7    -1.0         1.0    0.672355   \n",
              "8    -1.0         1.0    0.662112   \n",
              "9    -1.0         0.0    0.498863   \n",
              "10   -1.0         1.0    0.775831   \n",
              "11   -1.0         0.0    0.379827   \n",
              "12   -1.0         1.0    0.865065   \n",
              "\n",
              "                                                Tweet  \n",
              "0   @Adnan__786__ @AsYouNotWish Dont worry Indian ...  \n",
              "1   Academy of Sciences, eschews the normally sobe...  \n",
              "2                   I blew that opportunity -__- #mad  \n",
              "3        This time in 2 weeks I will be 30... _ÃÃ·Â´  \n",
              "4   #Deppression is real. Partners w/ #depressed p...  \n",
              "5   @POLITICOEurope Interesting choice of words......  \n",
              "6            @ananavarro CNN should, for sure _ÃÃ·Ã  \n",
              "7   Distance yourself once stretched by your frien...  \n",
              "8   Be happy. Be confident. Be kind.\\n\\n #Kissable...  \n",
              "9   My visit to hospital for care triggered #traum...  \n",
              "10  Thanks to Dollis Hill's relentless and tenacio...  \n",
              "11  @xxBambsxx @OriginalFunko @AshWillBradley @Ell...  \n",
              "12  @MPSNutrition Welcome to #MPSVT! We are deligh...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "Tk4Msn7DNd_3",
        "colab_type": "code",
        "outputId": "dbff60aa-f0c9-46ba-f46b-844ad5961ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "cell_type": "code",
      "source": [
        "df.Tweet.tolist()[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@Adnan__786__ @AsYouNotWish Dont worry Indian army is on its ways to dispatch all Terrorists to Hell',\n",
              " 'Academy of Sciences, eschews the normally sober tone of scientific papers and calls the massive loss of wildlife a Â\\x89Ã\\x9bÃ\\x8fbiological annihilation',\n",
              " 'I blew that opportunity -__- #mad',\n",
              " 'This time in 2 weeks I will be 30... _Ã\\x99Ã·Â´',\n",
              " '#Deppression is real. Partners w/ #depressed people truly dont understand the depth in which they affect us. Add in #anxiety &amp;makes it worse',\n",
              " '@POLITICOEurope Interesting choice of words... Are you confirming that governments fund #terrorism? Bit of an open door, but still...',\n",
              " '@ananavarro CNN should, for sure _Ã\\x99Ã·Ã\\x9b',\n",
              " 'Distance yourself once stretched by your friends impose! #serious #loveyou #notseriously',\n",
              " 'Be happy. Be confident. Be kind.\\\\n\\\\n #KissablesLoveSMShopmag\\\\nAllOutDenimFor KISSMARC',\n",
              " 'My visit to hospital for care triggered #trauma from accident 20+yrs ago and image of my dead brother in it. Feeling symptoms of #depression']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "AluPj7TiONOu",
        "colab_type": "code",
        "outputId": "36052414-0327-40b4-abae-7f860e042d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "cell_type": "code",
      "source": [
        "!cd sentiment-discovery; python3 pretrain.py --tokenizer-type SentencePieceTokenizer --vocab-size 32000 \\\n",
        "  --tokenizer-type SentencePieceTokenizer --tokenizer-path  ./../model/ama_32k_tokenizer/ama_32k_tokenizer.model "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "configuring data\n",
            "Creating mlstm\n",
            "* number of parameters: 218385729\n",
            "decaying None\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "Traceback (most recent call last):\n",
            "  File \"pretrain.py\", line 399, in <module>\n",
            "    main()\n",
            "  File \"pretrain.py\", line 350, in main\n",
            "    args, total_iters, skipped_iters, elapsed_time)\n",
            "  File \"pretrain.py\", line 205, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 102, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 90, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 3.91 GiB (GPU 0; 14.73 GiB total capacity; 13.96 GiB already allocated; 37.94 MiB free; 160.50 KiB cached)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YKRs5CNXNP9-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import collections\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from reparameterization import apply_weight_norm, remove_weight_norm\n",
        "\n",
        "from model import SentimentClassifier\n",
        "from configure_data import configure_data\n",
        "from arguments import add_general_args, add_model_args, add_classifier_model_args, add_run_classifier_args\n",
        "\n",
        "def get_data_and_args():\n",
        "    parser = argparse.ArgumentParser(description='PyTorch Sentiment Discovery Classification')\n",
        "    parser = add_general_args(parser)\n",
        "    parser = add_model_args(parser)\n",
        "    parser = add_classifier_model_args(parser)\n",
        "    data_config, data_parser, run_classifier_parser, parser = add_run_classifier_args(parser)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    args.cuda = torch.cuda.is_available()\n",
        "    args.shuffle=False\n",
        "\n",
        "    if args.seed is not -1:\n",
        "        torch.manual_seed(args.seed)\n",
        "        if args.cuda:\n",
        "            torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "    (train_data, val_data, test_data), tokenizer = data_config.apply(args)\n",
        "    args.data_size = tokenizer.num_tokens\n",
        "    args.padding_idx = tokenizer.command_name_map['pad'].Id\n",
        "    return (train_data, val_data, test_data), tokenizer, args\n",
        "\n",
        "def get_model(args):\n",
        "\n",
        "    sd = None\n",
        "    model_args = args\n",
        "    if args.load is not None and args.load != '':\n",
        "        sd = torch.load(args.load)\n",
        "        if 'args' in sd:\n",
        "            model_args = sd['args']\n",
        "        if 'sd' in sd:\n",
        "            sd = sd['sd']\n",
        "\n",
        "    ntokens = model_args.data_size\n",
        "    concat_pools = model_args.concat_max, model_args.concat_min, model_args.concat_mean\n",
        "    if args.model == 'transformer':\n",
        "        model = SentimentClassifier(model_args.model, ntokens, None, None, None, model_args.classifier_hidden_layers, model_args.classifier_dropout,\n",
        "                                      None, concat_pools, False, model_args)\n",
        "    else:\n",
        "        model = SentimentClassifier(model_args.model, ntokens, model_args.emsize, model_args.nhid, model_args.nlayers,\n",
        "                                      model_args.classifier_hidden_layers, model_args.classifier_dropout, model_args.all_layers, concat_pools, False, model_args)\n",
        "    args.heads_per_class = model_args.heads_per_class\n",
        "    args.use_softmax = model_args.use_softmax\n",
        "    try:\n",
        "        args.classes = list(model_args.classes)\n",
        "    except:\n",
        "        args.classes = [args.label_key]\n",
        "\n",
        "    try:\n",
        "        args.dual_thresh = model_args.dual_thresh and not model_args.joint_binary_train\n",
        "    except:\n",
        "        args.dual_thresh = False\n",
        "\n",
        "    if args.cuda:\n",
        "        model.cuda()\n",
        "\n",
        "    if args.fp16:\n",
        "        model.half()\n",
        "\n",
        "    if sd is not None:\n",
        "        try:\n",
        "            model.load_state_dict(sd)\n",
        "        except:\n",
        "            # if state dict has weight normalized parameters apply and remove weight norm to model while loading sd\n",
        "            if hasattr(model.lm_encoder, 'rnn'):\n",
        "                apply_weight_norm(model.lm_encoder.rnn)\n",
        "            else:\n",
        "                apply_weight_norm(model.lm_encoder)\n",
        "            model.lm_encoder.load_state_dict(sd)\n",
        "            remove_weight_norm(model)\n",
        "\n",
        "    if args.neurons > 0:\n",
        "        print('WARNING. Setting neurons %s' % str(args.neurons))\n",
        "        model.set_neurons(args.neurons)\n",
        "    return model\n",
        "\n",
        "# uses similar function as transform from transfer.py\n",
        "def classify(model, text, args):\n",
        "    # Make sure to set *both* parts of the model to .eval() mode. \n",
        "    model.lm_encoder.eval()\n",
        "    model.classifier.eval()\n",
        "    # Initialize data, append results\n",
        "    stds = np.array([])\n",
        "    labels = np.array([])\n",
        "    label_probs = np.array([])\n",
        "    first_label = True\n",
        "    heads_per_class = args.heads_per_class\n",
        "\n",
        "    def get_batch(batch):\n",
        "        text = batch['text'][0]\n",
        "        timesteps = batch['length']\n",
        "        labels = batch['label']\n",
        "        text = Variable(text).long()\n",
        "        timesteps = Variable(timesteps).long()\n",
        "        labels = Variable(labels).long()\n",
        "        if args.max_seq_len is not None:\n",
        "            text = text[:, :args.max_seq_len]\n",
        "            timesteps = torch.clamp(timesteps, max=args.max_seq_len)\n",
        "        if args.cuda:\n",
        "            text, timesteps, labels = text.cuda(), timesteps.cuda(), labels.cuda()\n",
        "        return text.t(), labels, timesteps-1\n",
        "\n",
        "    def get_outs(text_batch, length_batch):\n",
        "        if args.model.lower() == 'transformer':\n",
        "            class_out, (lm_or_encoder_out, state) = model(text_batch, length_batch, args.get_hidden)\n",
        "        else:\n",
        "            model.lm_encoder.rnn.reset_hidden(args.batch_size)\n",
        "            for _ in range(1 + args.num_hidden_warmup):\n",
        "                class_out, (lm_or_encoder_out, state) = model(text_batch, length_batch, args.get_hidden)\n",
        "        if args.use_softmax and args.heads_per_class == 1:\n",
        "            class_out = F.softmax(class_out, -1)\n",
        "        return class_out, (lm_or_encoder_out, state)\n",
        "\n",
        "\n",
        "    tstart = start = time.time()\n",
        "    n = 0\n",
        "    len_ds = len(text)\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(text), total=len(text)):\n",
        "            text_batch, labels_batch, length_batch = get_batch(data)\n",
        "            size = text_batch.size(1)\n",
        "            n += size\n",
        "            # get predicted probabilities given transposed text and lengths of text\n",
        "            probs, _ = get_outs(text_batch, length_batch)\n",
        "#            probs = model(text_batch, length_batch)\n",
        "            if first_label:\n",
        "                first_label = False\n",
        "                labels = []\n",
        "                label_probs = []\n",
        "                if heads_per_class > 1:\n",
        "                    stds = []\n",
        "            # Save variances, and predictions\n",
        "            # TODO: Handle multi-head [multiple classes out]\n",
        "            if heads_per_class > 1:\n",
        "                _, probs, std, preds = probs\n",
        "                stds.append(std.data.cpu().numpy())\n",
        "            else:\n",
        "                probs, preds = probs\n",
        "                if args.use_softmax:\n",
        "                    probs = F.softmax(probs, -1)\n",
        "            labels.append(preds.data.cpu().numpy())\n",
        "            label_probs.append(probs.data.cpu().numpy())\n",
        "\n",
        "            num_char = length_batch.sum().item()\n",
        "\n",
        "            end = time.time()\n",
        "            elapsed_time = end - start\n",
        "            total_time = end - tstart\n",
        "            start = end\n",
        "\n",
        "            s_per_batch = total_time / (i+1)\n",
        "            timeleft = (len_ds - (i+1)) * s_per_batch\n",
        "            ch_per_s = float(num_char) / elapsed_time\n",
        "\n",
        "    if not first_label:\n",
        "        labels = (np.concatenate(labels)) #.flatten())\n",
        "        label_probs = (np.concatenate(label_probs)) #.flatten())\n",
        "        if heads_per_class > 1:\n",
        "            stds = (np.concatenate(stds))\n",
        "        else:\n",
        "            stds = np.zeros_like(labels)\n",
        "    print('%0.3f seconds to transform %d examples' %\n",
        "                  (time.time() - tstart, n))\n",
        "    return labels, label_probs, stds\n",
        "\n",
        "def make_header(classes, heads_per_class=1, softmax=False, dual_thresh=False):\n",
        "    header = []\n",
        "    if softmax:\n",
        "        header.append('prediction')\n",
        "    for cls in classes:\n",
        "        if not softmax:\n",
        "            header.append(cls + ' pred')\n",
        "        header.append(cls + ' prob')\n",
        "        if heads_per_class > 1:\n",
        "            header.append(cls + ' std')\n",
        "    if dual_thresh:\n",
        "        header.append('neutral pred')\n",
        "        header.append('neutral prob')\n",
        "    return header\n",
        "\n",
        "def get_row(pred, prob, std, classes, heads_per_class=1, softmax=False, dual_thresh=False):\n",
        "    row = []\n",
        "    if softmax:\n",
        "        row.append(pred[0])\n",
        "    for i in range(len(classes)):\n",
        "        if not softmax:\n",
        "            row.append(pred[i])\n",
        "        row.append(prob[i])\n",
        "        if heads_per_class > 1:\n",
        "            row.append(std[i])\n",
        "    if dual_thresh:\n",
        "        row.append(pred[2])\n",
        "        row.append(prob[2])\n",
        "    return row \n",
        "\n",
        "def get_writer(preds, probs, stds, classes, heads_per_class=1, softmax=False, dual_thresh=False):\n",
        "    header = make_header(classes, heads_per_class, softmax, dual_thresh)\n",
        "    yield header\n",
        "    for pred, prob, std in zip(preds, probs, stds):\n",
        "        yield get_row(pred, prob, std, classes, heads_per_class, softmax, dual_thresh)\n",
        "\n",
        "def main():\n",
        "    (train_data, val_data, test_data), tokenizer, args = get_data_and_args()\n",
        "    model = get_model(args)\n",
        "\n",
        "    ypred, yprob, ystd = classify(model, train_data, args)\n",
        "\n",
        "    save_root = ''\n",
        "    save_root = os.path.join(save_root, args.save_probs)\n",
        "\n",
        "    print('saving predicted probabilities to '+save_root)\n",
        "    np.save(save_root, ypred)\n",
        "    np.save(save_root+'.prob', yprob)\n",
        "    np.save(save_root+'.std', ystd)\n",
        "\n",
        "    if args.write_results is None or args.write_results == '':\n",
        "        exit()\n",
        "\n",
        "    print('writing results to '+args.write_results)\n",
        "    writer = get_writer(ypred, yprob, ystd, args.classes, args.heads_per_class, args.use_softmax, args.dual_thresh)\n",
        "    train_data.dataset.write(writer, path=args.write_results)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-oL7lS_L6n0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}